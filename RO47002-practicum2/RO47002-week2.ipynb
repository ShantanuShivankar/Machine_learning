{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RO47002 Machine Learning for Robotics\n",
    "* (c) TU Delft, 2020\n",
    "* Period: 2020-2021, Q1\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/318952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_NUMBER = \"\"\n",
    "STUDENT_NAME1 = \"\"\n",
    "STUDENT_NUMBER1 = \"\"\n",
    "STUDENT_NAME2 = \"\"\n",
    "STUDENT_NUMBER2 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3f76d6a626db81c484191482b101edb",
     "grade": true,
     "grade_id": "cell-c35e4c8223095209",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert(GROUP_NUMBER != \"\")\n",
    "assert(STUDENT_NAME1 != \"\")\n",
    "assert(STUDENT_NUMBER1 != \"\")\n",
    "assert(STUDENT_NAME2 != \"\")\n",
    "assert(STUDENT_NUMBER2 != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you and your lab partner alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled practicum hours to ask a TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1b442ed6abad543fd0341e149a0f28e",
     "grade": false,
     "grade_id": "cell-6dfe7d328a3fc00c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Practicum 2\n",
    "* Before performing this practicum, work through Book chapters: 2, 3\n",
    "* **Deadline**: Sunday, September 20, 2020, 23:59\n",
    "\n",
    "## Objectives\n",
    "In this practicum, you and your lab partner will experiment with data collection, annotation, and turning a simple computer vision task into a machine learning problem.\n",
    "This practicum will not go very deep in machine learning theory, but is more intended to make you familiar with the broader context of how machine learning can be applied in robotics, and experience some practical steps in performing your own data collection.\n",
    "You will also demonstrate that you can perform several basic tasks with sklearn which have been explained in the book chapters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "597c1dc6b39e8b6d7c4d41c94c9eb65d",
     "grade": false,
     "grade_id": "cell-faaced7dc986d3ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The problem: a pen detector\n",
    "\n",
    "The context of this practicum is of a robot which will need to be able to pickup a pen from a desk or table. The robot has a basic down-facing camera that it can place on top of the desk to inspect an area of interest.\n",
    "The goal is to detect within this area where the pen is located, and how it is oriented. To do this, we formulate a multi-class classification problem: given a small image patch from the camera image, classifiy if this patch is the tip (start) of the pen, the end of the pen, the middle of the pen, or if it is just background. If we could succesfully classify all regions in the image, we would could determine the most probable image locations where the pen starts and ends, and thus its shape and orientation relative to the camera. With this information our robot has enough information to position and orient its (imaginary) grasper, and pick up the pen and put it in its pen collection.\n",
    "\n",
    "\n",
    "![Robot holding a pen](extra/grasping-robot.jpg)\n",
    "Image source: https://gigazine.net/gsc_news/en/20101221_robo_xero/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup common python stuff\n",
    "We will start by loading a few common python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import skimage.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00cc971d7a810d8bb4a317d8957110b5",
     "grade": false,
     "grade_id": "cell-aa9612c6df723c61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loading the images and annotations\n",
    "\n",
    "We start by listing the jpg files in the directory `images/mypen/`.\n",
    "If everything is correct, we should find 37 jpg images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def list_images(image_dir, filename_expression='*.jpg'):\n",
    "    filenames = glob.glob(os.path.join(image_dir, filename_expression))\n",
    "    filenames = sorted(filenames) # important for cross-platform compatiblity\n",
    "    print(f'Found {len(filenames)} image files in the directory \"{image_dir}\"')\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'images/mypen'\n",
    "\n",
    "# list all images. There should be 37 images in the images/mypen/ directory\n",
    "filenames = list_images(IMAGE_DIR)\n",
    "N = len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "113237ccacb775431347ad357d1278ea",
     "grade": false,
     "grade_id": "cell-f1bad3b730bcfc42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Le's see if we can load the first image and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if we can load and visualize an image here\n",
    "I = plt.imread(filenames[0])\n",
    "\n",
    "# this should show a picture of a pen\n",
    "plt.figure()\n",
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7041e875b0927de143ceb319e8fabf4",
     "grade": false,
     "grade_id": "cell-e0739afaa29cc360",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's start simple by creating 3 function to determine the width, height, and number of color channels of a loaded image. Channels wouls be 3 for a color image (Red, Green, Blue), and for instance 1 for a grayscale image.\n",
    "\n",
    "Note that images are loaded as numpy matrices, and hence pixels are indexed similar as mathematical arrays, i.e. (row, column). This means that the first dimension of the image goes into the vertical direction, and the second dimension into the horizontal direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94da11041047e6bc30a2512651250895",
     "grade": false,
     "grade_id": "cell-b8a4d9169e0e5919",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_image_width(I):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def get_image_height(I):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def get_image_channels(I):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea255154b9db2960e281df182614dbf1",
     "grade": true,
     "grade_id": "cell-9694201947b184c3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(get_image_width(I) == 1024)\n",
    "assert(get_image_height(I) == 768)\n",
    "assert(get_image_channels(I) == 3)\n",
    "\n",
    "I2 = np.swapaxes(I, 0, 1) # swap the width and height, but keep the 3rd (color channel) dimension in place\n",
    "assert(get_image_width(I2) == 768)\n",
    "assert(get_image_height(I2) == 1024)\n",
    "assert(get_image_channels(I2) == 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e042a69e3674d0df869d805168d6ccbb",
     "grade": false,
     "grade_id": "cell-d5d0cb8250fc679a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Load all images and annotations\n",
    "\n",
    "Previously, we found all images in the given directory. Now we are going to load all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Is = [plt.imread(filename) for filename in filenames]\n",
    "print('loaded %d images' % len(Is))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "698668cee3897bdb060058b46e7c4005",
     "grade": false,
     "grade_id": "cell-52c0d5f51edc9d0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the standard python `pickle` module, load the data annotations which are stored as a numpy array in `annots.npy` which is stored in the same directory as the images. You should use the built-in function in `pickle`, and you can find the documentation here: https://docs.python.org/3/library/pickle.html .\n",
    "If everything is correct, you will end up with a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a934993b435b5aa2965ab2df898c11db",
     "grade": false,
     "grade_id": "cell-9229c5719421dbc8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "annots = None # store your results in the variable `annots`\n",
    "annot_filename = os.path.join(IMAGE_DIR, 'annots.npy')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b3bf5b0cb9b7346459899a9b205356b",
     "grade": true,
     "grade_id": "cell-60b7105eea9e7370",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# if the annotations were correctly loaded, they should be a N x 4 numpy array\n",
    "assert(type(annots) == np.ndarray)\n",
    "assert(annots.shape == (37, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9502dd7a9fbd939253a2616e37f8ef7",
     "grade": false,
     "grade_id": "cell-91a0b3ce2d144155",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once we sucessfully loaded all images and annotations, we are now ready to implement a function to plot them. We can use `matplotlib.pyplot` (https://matplotlib.org/3.3.1/api/pyplot_summary.html) for this, which provides a very similar interface to the plotting commands found in Matlab.\n",
    "\n",
    "In this plotting routine, you should execute the following steps:\n",
    "\n",
    "1. show the image, plot the following steps on top of the image\n",
    "1. plot point p1 as a green circle, with markersize 10, and label \"tip\"\n",
    "1. plot point p2 as a red circle, with markersize 10, and label \"end\"\n",
    "1. plot a cyan line starts at one point and end at another, give it linewdith 2 for better visualization\n",
    "1. Add a legend (pro-tip: if you use the \"label\" keyword to the plot() commands to [simplify creating the legend](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.legend.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c47e319b3e59a2ae1efde8e6c068cc19",
     "grade": true,
     "grade_id": "cell-01144d0a52bac1d6",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def show_annotation(I, p1, p2):\n",
    "    plt.figure()\n",
    "    \n",
    "    # show the image\n",
    "    # plot point p1 as a green circle, with markersize 10, and label \"tip\"\n",
    "    # plot point p2 as a red circle, with markersize 10, and label \"end\"\n",
    "    # plot a line starts at one point and end at another. \n",
    "    # Use a suitable color and linewidth for better visualization\n",
    "    # Add a legend (tip, you can use the \"label\" keyword when you plot a point)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # done, show the image\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct, this call to `show_annotation()` below should show a similar image as this reference:\n",
    "![reference to first image](extra/reference_annotation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7fdaff88a2fb54a0e59fc38aae1c49b",
     "grade": false,
     "grade_id": "cell-d2c44842763a2d81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "I = Is[img_idx]\n",
    "p1 = annots[img_idx,:2].copy() # point 1, tip of the pen\n",
    "p2 = annots[img_idx,2:].copy() # point 2, end of the pen\n",
    "\n",
    "show_annotation(I, p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d07d8eec59c62dbd356bba1a0d3987ed",
     "grade": false,
     "grade_id": "cell-93a3e6a0d50390ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Use annotations to extract and label patches\n",
    "\n",
    "We will extract from each image a bunch of image patches of $100 \\times 100$ pixels.\n",
    "In a moment we will introduce some function to determine at which locations in the images will shall extract the image patches, but first you will need to write a few lines of code which:\n",
    "\n",
    "- takes as first input `I`: an RGB image \n",
    "- takes as second input `p`: a 2D location in pixel coordinates\n",
    "- returns the $100 \\times 100 \\times 3$ image patch centered around pixel coordinates p\n",
    "\n",
    "To extract an image patch, you can use array slicing.\n",
    "Note that point p will be given as a 2-dimensional floating point numpy vector. You should cast the elements to `int` types before you can use them to slice an array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fb6822b06af9312b03a5cb03c1b9d3d",
     "grade": false,
     "grade_id": "cell-73e36739d6f7c1a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# the size of the patch in pixels\n",
    "WIN_SIZE = (100, 100, 3)\n",
    "\n",
    "# for convenience, half the window\n",
    "HALF_WIN_SIZE = (WIN_SIZE[0] // 2, WIN_SIZE[1] // 2, WIN_SIZE[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "806ba9ae4cc335ee488faae6ac22e848",
     "grade": false,
     "grade_id": "cell-66851531c72ea489",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_patch_at_point(I, p):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your solution, let's extract the patch around the annotated tip of the pen. If everything is correct, you should be able to see the tip similar to this reference image: ![reference patch](extra/reference_patch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7364cf4637b36f60e274509ea1534330",
     "grade": true,
     "grade_id": "cell-1680c0fa41e66dbd",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "P = get_patch_at_point(I, p1)\n",
    "plt.imshow(P)\n",
    "plt.show()\n",
    "\n",
    "assert(get_image_width(P) == 100)\n",
    "assert(get_image_height(P) == 100)\n",
    "assert(get_image_channels(P) == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d50c91a9a7032a9d741e1212c3adde93",
     "grade": false,
     "grade_id": "cell-616aea3b289ef53b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Transform patches into feature vectors\n",
    "\n",
    "Next, we are going to perform a simple transformation of the extracted patches. An input image patch should be transformed into a vector. \n",
    "To do so, complete the `patch_to_vec` function which takes an image patch as input, and should return a vector $x$,\n",
    "which will be the feature vector for our machine learning experiments.\n",
    "The function should do the following:\n",
    "\n",
    "1. Resize the patch to a $9 \\times 9 \\times 3$ image. To resize the image (patch), `skimage.transform` might contain a useful function, check the documentation here: https://scikit-image.org/docs/dev/api/skimage.transform.html. Note that we do not want to use any anti_aliasing features, since these are slow and we need to convert many patches.\n",
    "\n",
    "2. After downsizing the patch, reshape or flatten the patch (which is a 3-dimensional [tensor](https://nl.wikipedia.org/wiki/Tensor)) to a vector (i.e. a 1-dimensional tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81c499864e6d5359141b6bcef1e5e937",
     "grade": false,
     "grade_id": "cell-0cf0f94cd3a5d5a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# the target size of the patches after downsizing\n",
    "FEAT_SIZE = (9,9,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08d5809eadacdf362575a61dffc0478c",
     "grade": false,
     "grade_id": "cell-7fd750828ba3a31f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def patch_to_vec(P):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** How many dimensions will the resulting feature space have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67e5f947649d0aaec36ed795c0c24c19",
     "grade": false,
     "grade_id": "cell-ebffac303eaefbee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "number_of_feature_dimensions = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f'This will be a {number_of_feature_dimensions}-dimensional feature space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "819e48dcd149ee7affd842f09a042d97",
     "grade": true,
     "grade_id": "cell-a14eb6f5c755ea94",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bec2ae3c49c2e7842cb974615bd9c94",
     "grade": false,
     "grade_id": "cell-f1094c44127c8138",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Sample locations in image to extract patches\n",
    "\n",
    "From each image we will extract multiple image patches. Some of the patches will contain background, and others will contain parts of the pen.\n",
    "We will consider two strategies to sample patch locations from an image:\n",
    "\n",
    "1. sample in a uniform grid across the image\n",
    "2. also sample some points as in strategy 1, but select additional points around the pen\n",
    "\n",
    "We'll also add some random offsets to the pixel coordinates of the sampled locations to add some more variance,\n",
    "and avoid accidentally having the exact same image location multiple times.\n",
    "The code to implement these sampling strategies has already been given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4aedb76a3821a4f341d71f6d45c8bf38",
     "grade": false,
     "grade_id": "cell-31ef718910808767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sample_points_grid(I):\n",
    "    # window centers\n",
    "    W = get_image_width(I)\n",
    "    H = get_image_height(I)\n",
    "    \n",
    "    step_size = (WIN_SIZE[0]//2, WIN_SIZE[1]//2)\n",
    "    min_ys = range(0, H-WIN_SIZE[0]+1, step_size[0])\n",
    "    min_xs = range(0, W-WIN_SIZE[1]+1, step_size[1])\n",
    "    center_ys = range(HALF_WIN_SIZE[0], H-HALF_WIN_SIZE[0]+1, step_size[0])\n",
    "    center_xs = range(HALF_WIN_SIZE[1], W-HALF_WIN_SIZE[1]+1, step_size[1])\n",
    "    centers = np.array(np.meshgrid(center_xs, center_ys))\n",
    "    centers = centers.reshape(2,-1).T\n",
    "    centers = centers.astype(float) \n",
    "    \n",
    "    # add a bit of random offset\n",
    "    centers += np.random.rand(*centers.shape) * 10 \n",
    "    \n",
    "    # discard points close to border where we can't extract patches\n",
    "    centers = remove_points_near_border(I, centers)\n",
    "    \n",
    "    return centers\n",
    "\n",
    "def sample_points_around_pen(I, p1, p2):\n",
    "    Nu = 100 # uniform samples (will mostly be background, and some non-background)\n",
    "    Nt = 50 # samples at target locations, i.e. near start, end, and middle of pen\n",
    "    \n",
    "    target_std_dev = np.array(HALF_WIN_SIZE[:2])/3 # variance to add to locations\n",
    "\n",
    "    upoints = sample_points_grid(I)\n",
    "    idxs = np.random.choice(upoints.shape[0], Nu)\n",
    "    upoints = upoints[idxs,:]\n",
    "    \n",
    "    \n",
    "    # sample around target locations\n",
    "    tpoints1 = np.random.randn(Nt,2)\n",
    "    tpoints1 = tpoints1 * target_std_dev + p1\n",
    "\n",
    "    tpoints2 = np.random.randn(Nt,2)\n",
    "    tpoints2 = tpoints2 * target_std_dev + p2\n",
    "\n",
    "    # sample over length pen\n",
    "    alpha = np.random.rand(Nt)\n",
    "    tpoints3 = p1[None,:] * alpha[:,None] + p2[None,:] * (1. - alpha[:,None])\n",
    "    tpoints3 = tpoints3 + np.random.randn(Nt,2) * target_std_dev\n",
    "    \n",
    "    # merge all points\n",
    "    points = np.vstack((upoints, tpoints1, tpoints2, tpoints3))\n",
    "    \n",
    "    # discard points close to border where we can't extract patches\n",
    "    points = remove_points_near_border(I, points)\n",
    "    \n",
    "    return points\n",
    "\n",
    "def remove_points_near_border(I, points):\n",
    "    W = get_image_width(I)\n",
    "    H = get_image_height(I)\n",
    "\n",
    "    # discard points that are too close to border\n",
    "    points = points[points[:,0] > HALF_WIN_SIZE[1],:]\n",
    "    points = points[points[:,1] > HALF_WIN_SIZE[0],:]\n",
    "    points = points[points[:,0] < W - HALF_WIN_SIZE[1],:]\n",
    "    points = points[points[:,1] < H - HALF_WIN_SIZE[0],:]\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to understand the difference between these two sampling strategies is to visualize the patch locations that they generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points1 = sample_points_grid(I) # sampling strategy 1\n",
    "points2 = sample_points_around_pen(I, p1, p2) # sampling strategy 2\n",
    "\n",
    "# plot both sampling strategies in a single figure using subplots\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(I)\n",
    "plt.plot(points1[:,0], points1[:,1], 'w.')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(I)\n",
    "plt.plot(points2[:,0], points2[:,1], 'w.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the labels of a patch,\n",
    "we'll consider the distance of the patch's center to the tip of the pen (class 1),\n",
    "to the end of the pen (class 2), or to the middle of the pen (class 3).\n",
    "We will assign the class label based on which distance is the shortest,\n",
    "but only if this shortest distance is under a certain threshold since the pen should still be visible within the patch.\n",
    "If the patch is too far away from the pen, we will mark it as background (class 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\n",
    "    'background', # class 0\n",
    "    'tip',        # class 1\n",
    "    'end',        # class 2\n",
    "    'middle'      # class 3\n",
    "]\n",
    "\n",
    "def make_labels_for_points(I, p1, p2, points):\n",
    "    \"\"\" Determine the class label (as an integer) on point distance to different parts of the pen \"\"\"\n",
    "    num_points = points.shape[0]\n",
    "    \n",
    "    # for all points ....\n",
    "    \n",
    "    # ... determine their distance to tip of the pen\n",
    "    dist1 = points - p1\n",
    "    dist1 = np.sqrt(np.sum(dist1 * dist1, axis=1))\n",
    "    \n",
    "    # ... determine their distance to end of the pen\n",
    "    dist2 = points - p2\n",
    "    dist2 = np.sqrt(np.sum(dist2 * dist2, axis=1))\n",
    "\n",
    "    # ... determine distance to pen middle\n",
    "    alpha = np.linspace(0.2, 0.8, 100)\n",
    "    midpoints = p1[None,:] * alpha[:,None] + p2[None,:] * (1. - alpha[:,None]) \n",
    "    dist3 = scipy.spatial.distance_matrix(midpoints, points)\n",
    "    dist3 = np.min(dist3, axis=0)\n",
    "    \n",
    "    # the class label of a point will be determined by which distance is smallest\n",
    "    #    and if that distance is at least below `dist_thresh`, otherwise it is background\n",
    "    dist_thresh = WIN_SIZE[0] * 2./3.\n",
    "\n",
    "    # store distance to closest point in each class in columns\n",
    "    class_dist = np.zeros((num_points, 4))\n",
    "    class_dist[:,0] = dist_thresh\n",
    "    class_dist[:,1] = dist1\n",
    "    class_dist[:,2] = dist2\n",
    "    class_dist[:,3] = dist3\n",
    "    \n",
    "    # the class label is now the column with the lowest number\n",
    "    labels = np.argmin(class_dist, axis=1)\n",
    "    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labeled_points(points, labels):\n",
    "    plt.plot(points[labels == 0, 0], points[labels == 0, 1], 'r.', label=CLASS_NAMES[0])\n",
    "    plt.plot(points[labels == 1, 0], points[labels == 1, 1], 'g.', label=CLASS_NAMES[1])\n",
    "    plt.plot(points[labels == 2, 0], points[labels == 2, 1], 'b.', label=CLASS_NAMES[2])\n",
    "    plt.plot(points[labels == 3, 0], points[labels == 3, 1], 'y.', label=CLASS_NAMES[3])\n",
    "\n",
    "labels1 = make_labels_for_points(I, p1, p2, points1)\n",
    "labels2 = make_labels_for_points(I, p1, p2, points2)\n",
    "\n",
    "plt.figure(figsize=(10,12))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(I)\n",
    "plot_labeled_points(points1, labels1)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(I)\n",
    "plot_labeled_points(points2, labels2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the images, the sampling strategies result in different amount of patches being extracted. In the first strategy, for instance, there are many more \"background\" patches than in the second one.\n",
    "\n",
    "To make this more conrete, determine the number of samples of each class in `labels1` and `labels2`,\n",
    "complete the function `count_classes(labels)` below, which for a given array of `labels` creates a 4-dimensional numpy vector, where the i-th element contains the number of times that class occurs in `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d354777f8c3a4cfeb567628a1cac0ff",
     "grade": false,
     "grade_id": "cell-bb459267b8ad750c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def count_classes(labels):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return counts\n",
    "\n",
    "class_counts1 = count_classes(labels1)\n",
    "class_counts2 = count_classes(labels2)\n",
    "print('class occurrences with strategy 1:', class_counts1)\n",
    "print('class occurrences with strategy 2:', class_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17418bc1c4a428165efd74a68e834ee4",
     "grade": true,
     "grade_id": "cell-44670b8d33ec52b9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(np.all(count_classes([3,0,2,3,1,0]) == [2,1,1,2])) # 2 zeros, 1 one, 1 two, 2 threes\n",
    "assert(np.all(count_classes([3,2,1,2]) == [0,1,2,1])) # 0 zeros, 1 one, 2 twos, 1 three\n",
    "\n",
    "# dtype of resulting array should be integer\n",
    "cnt = count_classes([3,2,1,2])\n",
    "assert(np.issubdtype(cnt.dtype, np.integer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from these numbers that in strategy 1 one classes is very frequent, and the others much less so. With strategy 2, the classes are more uniformly distributed.\n",
    "\n",
    "As an exercise, we can try to express the amount of 'uniformity' in a distribution using a key concept from information theory: *entropy*. This concept is also related to the concept of *cross-entropy* which you will learn about more later in the course. On YouTube you can find [a good video introduction on entropy and cross-entropy](https://www.youtube.com/watch?v=ErfnhcEV1O8).\n",
    "For now, it suffices to state that entropy measures the amount of 'surprise' or 'uncertainty' we would have about the outcome if we would sample from a given distribution. For instance, if the distribution over the four classes would be so skewed that all samples belong to one class, the entropy would be 0 as there would be no surprise what class label we would see if we take a random sample.\n",
    "On the other hand, the maximum entropy is achieved when all classes are completely equally likely to occur, i.e. the class labels would be uniformly distributed.\n",
    "\n",
    "So, to compute the entropy of the class label counts of the two sampling strategies, first implement the following two functions:\n",
    "1. a function `class_probs(counts)` which takes the class occurence `counts`, and return a distribution vector $\\boldsymbol{p} = [p_1, p_2, p_3, p_4]$ , i.e. a vector of the same length (number of classes), with elements $p_c \\in [0,1]$ which sum up to 1, $\\sum_c p_c = 1$. Each element $p_c$ represent the class probability $P(c)$ that a sample in the distribution has class label $c$.\n",
    "2. an `entropy(p)` function which takes a class distribution vector `p`, and computes the entropy for that distribution. The formula will be given below.\n",
    "\n",
    "Afterwards, you can compute the entropy of each strategy,\n",
    "and compared to the theoretic maximum entropy for a perfectly uniform distribution over the four classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08164a8068e285efb7be6ae4d61622ef",
     "grade": false,
     "grade_id": "cell-d831c1b0b71a897f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def class_probs(counts):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6452767fab0cb2bf906886c89c96c01f",
     "grade": true,
     "grade_id": "cell-96aa8af031dfe0ba",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check uniform class distribution\n",
    "test_dist_1 = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "assert(np.all(class_probs(np.array([1,1,1,1])) == test_dist_1))\n",
    "assert(np.all(class_probs(np.array([100,100,100,100])) == test_dist_1))\n",
    "\n",
    "# check non-uniform distributions\n",
    "test_dist_2 = np.array([0., 1., 0., 0.])\n",
    "assert(np.all(class_probs(np.array([0,42,0,0])) == test_dist_2))\n",
    "\n",
    "test_dist_3 = np.array([0., 0.5, 0., 0.5])\n",
    "assert(np.all(class_probs(np.array([0,1,0,1])) == test_dist_3))\n",
    "\n",
    "# should sum up to one for any given of class counts\n",
    "assert(np.sum(class_probs(np.array([36,20,9,412]))) == 1)\n",
    "assert(np.all(class_probs(np.array([36,20,9,412]))) > 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the [*entropy*](https://en.wikipedia.org/wiki/Entropy_(information_theory)) function.\n",
    "\n",
    "The formula for entropy that this function should implement is:\n",
    "$H = - \\sum_c P(c) log(P(c)) $.\n",
    "\n",
    "Note that this formula assumes that all classes have at least a non-zero chance of occurring, and you might run into numeric issues if $P(c) = 0$ for one or more classes $c$. The best thing to do is to remove any zero-probability classes if they occur.\n",
    "\n",
    "For this exercise, you must implement this function yourself. You can numpy functions, but not any other statistical python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afc4f12fd300e39c6d1e36802664c575",
     "grade": false,
     "grade_id": "cell-89c7dc098110ebff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "387092e673b8e64178a52dfbd7d88b58",
     "grade": true,
     "grade_id": "cell-f263f87aced77223",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1-class test case\n",
    "#  (only one class distribution possible)\n",
    "assert(entropy(np.array([1.0])) == 0)\n",
    "\n",
    "# 2-class cases\n",
    "# entropy of [0.5, 0.5] is approx 0.6931\n",
    "assert(entropy(np.array([0.5, 0.5])) == -np.log(0.5))\n",
    "assert(entropy(np.array([1.0, 0.0])) == 0)\n",
    "# NOTE: if this test above doesn't work,\n",
    "# you may still need to remove the elements with probability 0 from the input vector p\n",
    "\n",
    "# 3-class test cases\n",
    "# entropy of [0.1, 0.6, 0.3] is approx 0.89794572\n",
    "assert(np.abs(entropy(np.array([0.1, 0.6, 0.3])) - 0.897945)<1e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aba0bfd7e82215de2de7f8350080df47",
     "grade": false,
     "grade_id": "cell-0789c91d2718e943",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ANSWER_STRATEGY1_ENTROPY = None\n",
    "ANSWER_STRATEGY2_ENTROPY = None\n",
    "ANSWER_MAX_FOUR_CLASS_ENTROPY = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f727f825af36e003b96fa30359e81d9c",
     "grade": true,
     "grade_id": "cell-3cf6aeaacc57fb90",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Your computed results:')\n",
    "print('          Entropy for labels in strategy 1:', ANSWER_STRATEGY1_ENTROPY)\n",
    "print('          Entropy for labels in strategy 2:', ANSWER_STRATEGY2_ENTROPY)\n",
    "print('max. Entropy for four classes distribution:', ANSWER_MAX_FOUR_CLASS_ENTROPY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct, the results you computed should confirm that the labels obtained with strategy 2 has an entropy close to the theoretic maximum, and thus is in an objective sense more uniformly distribution than the class labels obtained with strategy 1.\n",
    "\n",
    "We will revisit entropy in future lectures and (Book) exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put it all together\n",
    "\n",
    "Finally, we put all the preceding steps together to construct our a set of feature vectors from a given raw dataset of images. The following code performs the following steps:\n",
    "\n",
    "* For each image in our dataset, do the following\n",
    "    1. select patch locations, using one of the two strategies\n",
    "    2. determine the class label for each location, considering the image annotations\n",
    "    3. extract the image patches at the selected locations\n",
    "    4. convert each image patches to a feature vector\n",
    "* Concatenate all features and labels from the images together in one data matrix X, and one large label vector\n",
    "* Also, for each feature vector we keep track in `imgids` from which image it was extracted, and in `points` at which pixel coordinate the patch was located. This will help us later to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(I, p1, p2, strategy=None):\n",
    "    \n",
    "    # by default, if no strategy is explicitly defined, use strategy 2\n",
    "    if strategy == 1:\n",
    "        points = sample_points_grid(I)\n",
    "    if strategy == 2 or strategy is None:\n",
    "        points = sample_points_around_pen(I, p1, p2)\n",
    "    \n",
    "    # determine the labels of the points\n",
    "    labels = make_labels_for_points(I, p1, p2, points)\n",
    "    \n",
    "    xs = []\n",
    "    for p in points:\n",
    "        P = get_patch_at_point(I, p)\n",
    "        x = patch_to_vec(P)\n",
    "        xs.append(x)\n",
    "    X = np.array(xs)\n",
    "\n",
    "    return X, labels, points\n",
    "\n",
    "def extract_multiple_images(idxs, strategy=None):\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    points = []\n",
    "    imgids = []\n",
    "\n",
    "    for step, idx in enumerate(idxs):\n",
    "        I = Is[idx]\n",
    "        I_X, I_y, I_points = extract_patches(I, annots[idx,:2], annots[idx,2:], strategy=strategy)\n",
    "\n",
    "        classcounts = count_classes(I_y)\n",
    "        print(f'image {idx}, class count = {classcounts}')\n",
    "\n",
    "        Xs.append(I_X)\n",
    "        ys.append(I_y)\n",
    "        points.append(I_points)\n",
    "        imgids.append(np.ones(len(I_y),dtype=int)*idx)\n",
    "\n",
    "    Xs = np.vstack(Xs)\n",
    "    ys = np.hstack(ys)\n",
    "    points = np.vstack(points)\n",
    "    imgids = np.hstack(imgids)\n",
    "    \n",
    "    return Xs, ys, points, imgids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now construct the actual training and test data from the images:\n",
    "- training data will consist of the first 26 images\n",
    "- test data consists of the remaining 11 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = list(range(0,26))\n",
    "test_imgs = list(range(26,len(Is)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, points_train, imgids_train = extract_multiple_images(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, points_test, imgids_test = extract_multiple_images(test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's add a simple interactive ipython widget to quickly inspect the images, and the sampled locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gt_labels(idx):\n",
    "    I = Is[idx]\n",
    "    \n",
    "    I_points = points_train[imgids_train == idx,:]\n",
    "    I_ys = y_train[imgids_train == idx]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(I)\n",
    "    plot_labeled_points(I_points, I_ys)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "ipywidgets.interact(show_gt_labels, idx=(0,len(train_imgs)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(Ps, labels):\n",
    "    uls = np.unique(labels)\n",
    "    nclasses = len(uls)\n",
    "    nsamples = 12\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    for lidx, label in enumerate(uls):\n",
    "        idxs = np.where(labels == label)[0]\n",
    "        idxs = np.random.choice(idxs, nsamples, replace=False)\n",
    "        \n",
    "        for j, idx in enumerate(idxs):\n",
    "            P = Ps[idx,:]\n",
    "            P = P.reshape(FEAT_SIZE)\n",
    "            \n",
    "            plt.subplot(nclasses, nsamples, lidx*nsamples+j+1)\n",
    "            plt.imshow(P, clim=(0,1))\n",
    "            plt.axis('off')\n",
    "            plt.title('label: %d' % label)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "plot_samples(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4249d135eab84d5c7cb0ab273643aeba",
     "grade": false,
     "grade_id": "cell-cee8badefc4db3a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Shortlist promising models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2579dd2e4517da1268732aefb4d1cc39",
     "grade": false,
     "grade_id": "cell-bdfcccec57580b4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's train some classifiers.\n",
    "\n",
    "* a *Logistic Regression classsifier* using the `SGDClassifier` class in the `linear_model` package of sklearn. See also Chapter 3 of the book. Call the classifier object `sgd_clf`. Look into the documentation of `SGDClassifier` to see how to set the loss to the logistic regression loss.\n",
    "* a *Decision Tree* using `DecisionTreeClassifier`. Note that Chapter 2 used the related `DecisionTreeRegressor`, which uses a similar approach, but then for regression\n",
    "* a *Random Forest* using `RandomForestClassifier`. See also Chapter 2.\n",
    "\n",
    "You may need to import the relevant modules from `sklearn`.\n",
    "\n",
    "PS.: Do NOT train the classifiers yet, we'll do that in a cell block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebe6ab8ceaba4207689687a74c7eb630",
     "grade": false,
     "grade_id": "cell-d9b0bcd8c61fda5d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sgd_clf = None # this should be the name of your solution code\n",
    "dt_clf = None # this should be the Decision Tree classifer\n",
    "rf_clf = None # this should be the Random Forest classifier\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7de0d106c99ecd9c53877726cdd768b5",
     "grade": true,
     "grade_id": "cell-7f5fbdaa5a4166a8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e535d04cacc3c4cb9cefc4633641fda9",
     "grade": false,
     "grade_id": "cell-791d0c1b2ef5f35f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Train each classifier on the training data `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58dabb662f5c61e387e6b49d0965bf9f",
     "grade": false,
     "grade_id": "cell-3dc58e1c3955fce3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train the classifiers here\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cbabb336a1748c4d36c135192d3a270",
     "grade": true,
     "grade_id": "cell-17855f34550397f1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(sgd_clf.n_iter_ > 0) # NOTE: n_iter_ will not exist untill training\n",
    "assert(dt_clf.n_features_ > 0) # NOTE: n_features_ will not exist untill training\n",
    "assert(rf_clf.n_features_ > 0) # NOTE: n_features_ will not exist untill training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c98e808ea14c9127bbf0f242120ae33",
     "grade": false,
     "grade_id": "cell-d0de90bcabc83ccf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "We start evaluation by just focusing on the Logistic Regression, and see what the accuracy is on the **training data** on which it was optimized on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d829626ecc58adb1437eeadf17672e63",
     "grade": false,
     "grade_id": "cell-555ed48a951e3f77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# predict the class labels of the linear classifier on the training data\n",
    "\n",
    "y_train_pred = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bba974103fcf569f6580379098dc45e8",
     "grade": true,
     "grade_id": "cell-054663ba6b7fac4d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9e8e2b987b7f6f99bdb861fc41f78ea",
     "grade": false,
     "grade_id": "cell-ee32c430fe5d85f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To compute the accuracy of the prediction, we can use `accuracy_score` from sklearn. However, you should first show that you know how to implement the accuracy yourself. Therefore implement a function `my_accuracy_score` which behaves like sklearn's `accuracy_score`, but do so without using any functions from sklearn modules. You may use numpy if you want to in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "825b257e74e5695bb1a668f94b8b3691",
     "grade": false,
     "grade_id": "cell-924779c6846e265c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def my_accuracy_score(y, y_pred):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('Sklearns accuracy:', sklearn.metrics.accuracy_score(y_train, y_train_pred))\n",
    "print('    Your accuracy:', my_accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dc88d0b3507f54ed577523fcadee207",
     "grade": true,
     "grade_id": "cell-a8ae49a9a7a2a4de",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "assert(my_accuracy_score(y_train, y_train_pred) == accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# let's also try some dummy values\n",
    "assert(my_accuracy_score([1,2,4,2,3,2,2], [4,2,4,4,3,2,1]) == 4./7.)\n",
    "# this should also work with numpy arrays\n",
    "assert(my_accuracy_score(np.array([1,2,4,2,3,2,2]), np.array([4,2,4,4,3,2,1])) == 4./7.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c80f1787e41138e0eaa22c497c012d20",
     "grade": false,
     "grade_id": "cell-8db5b939b2a45d48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ok, let's create a function to put these steps together, so we can easily evaluate any classifier on a given labeled dataset (X,y).\n",
    "As part of the performance statistics, let's report the accuracy and the confusion matrix.\n",
    "You do not need to compute the confusion matrix manually, you can use the builtin function from sklearn for this. You are also free to use sklearn's `accuracy_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24ba8511e99017721adc3248d63e4dbd",
     "grade": false,
     "grade_id": "cell-9d8e355a50c1a672",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You may want need to import some stuff from sklearn here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "def eval_classifier(clf, X, y):\n",
    "    accuracy = None # compute this (you can use sklearn)\n",
    "    confmat = None # compute this (you can use sklearn)\n",
    "\n",
    "    # do something with classifier `clf` here\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return accuracy, confmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now easily check how all classifiers perform on **the training data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5065abcaedef1d9349643a05c63fa76c",
     "grade": true,
     "grade_id": "cell-160b3b9153373608",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def report_eval(name, accuracy, confmat):\n",
    "    print(f'*** {name} ***')\n",
    "    print(f' confusion matrix:')\n",
    "    print(confmat)\n",
    "    print(f' accuracy: {accuracy:.3f}')\n",
    "    print()\n",
    "\n",
    "print('-- TRAINING data evaluation --')\n",
    "print()\n",
    "\n",
    "# logistic regression\n",
    "sgd_train_accuracy, sgd_train_confmat = eval_classifier(sgd_clf, X_train, y_train)\n",
    "report_eval('Logistic Regression', sgd_train_accuracy, sgd_train_confmat)\n",
    "\n",
    "# decision tree\n",
    "dt_train_accuracy, dt_train_confmat = eval_classifier(dt_clf, X_train, y_train)\n",
    "report_eval('Decision Tree', dt_train_accuracy, dt_train_confmat)\n",
    "\n",
    "# random forest\n",
    "rf_train_accuracy, rf_train_confmat = eval_classifier(rf_clf, X_train, y_train)\n",
    "report_eval('Random Forest', rf_train_accuracy, rf_train_confmat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82189f41cb714c537aa8ce2c6caf3724",
     "grade": false,
     "grade_id": "cell-693b531bd94807a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the same function to evaluate how each of the three classifiers perform on **the TEST data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- TEST data evaluation --')\n",
    "print()\n",
    "\n",
    "# logistic regression\n",
    "sgd_test_accuracy, sgd_test_confmat = eval_classifier(sgd_clf, X_test, y_test)\n",
    "report_eval('Logistic Regression', sgd_test_accuracy, sgd_test_confmat)\n",
    "\n",
    "# decision tree\n",
    "dt_test_accuracy, dt_test_confmat = eval_classifier(dt_clf, X_test, y_test)\n",
    "report_eval('Decision Tree', dt_test_accuracy, dt_test_confmat)\n",
    "\n",
    "# random forest\n",
    "rf_test_accuracy, rf_test_confmat = eval_classifier(rf_clf, X_test, y_test)\n",
    "report_eval('Random Forest', rf_test_accuracy, rf_test_confmat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd04ce3dbe86b0079b449e87c81fb6a7",
     "grade": true,
     "grade_id": "cell-67278acc92daacc3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Based on these results, which of these classifiers is overfitting most?\n",
    "\n",
    "Answer by only uncommenting the correct answer in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67c5243d4dcefd0231f29cd8598d8ee0",
     "grade": false,
     "grade_id": "cell-bae06c57218b6e4b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer by uncommenting only the correct option from this block below\n",
    "ANSWER_OVERFITTING_MOST = 'no answer given yet ...'\n",
    "#ANSWER_OVERFITTING_MOST = 'Logistic Regression'\n",
    "#ANSWER_OVERFITTING_MOST = 'Decision Tree'\n",
    "#ANSWER_OVERFITTING_MOST = 'Random Forest'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56097f1585af03bd18952cd14bfe5dda",
     "grade": true,
     "grade_id": "cell-d0dae5593abdc443",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Your answer: ', ANSWER_OVERFITTING_MOST)\n",
    "\n",
    "# to answer, you should have selected one of the three options ...\n",
    "assert(ANSWER_OVERFITTING_MOST in ('Logistic Regression', 'Decision Tree', 'Random Forest'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on the training data is not giving us a realistic view of the performance of the classifier on the new (test) data. However, we should avoid to rely on our test data to perform model selection or hyperparameter optimization. You have learned of a better approach to estimate the test performance without using the test data, but by using the training data only (!). Use this strategy to get an expected value and standard deviation for the test accuracy.\n",
    "\n",
    "Note: you can use the default settings that sklearn provides for its implementation of this strategy, only make sure you estimate the `accuracy` and not some other metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21824cbc8cb70db4259ccf144843b03d",
     "grade": false,
     "grade_id": "cell-7ea84cd80ed16727",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You may want need to import some stuff from sklearn here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "def predict_classifier_test_accuracy(clf, X_train, y_train):\n",
    "    mean_accuracy = None # determine this\n",
    "    stddev_accuracy = None # determine this\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return mean_accuracy, stddev_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9542987748a0059f5cf19160fce4d09",
     "grade": true,
     "grade_id": "cell-8de1c0126364d46f",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's see if it works. NOTE: this may take a while ...\n",
    "\n",
    "sgd_mean_accuracy, sgd_stddev_accuracy = predict_classifier_test_accuracy(sgd_clf, X_train, y_train)\n",
    "print('*** Logistic Regression ***')\n",
    "print('    Mean:', sgd_mean_accuracy)\n",
    "print('Std.dev.:', sgd_stddev_accuracy)\n",
    "print()\n",
    "\n",
    "dt_mean_accuracy, dt_stddev_accuracy = predict_classifier_test_accuracy(dt_clf, X_train, y_train)\n",
    "print('*** DT Classifier ***')\n",
    "print('    Mean:', dt_mean_accuracy)\n",
    "print('Std.dev.:', dt_stddev_accuracy)\n",
    "print()\n",
    "\n",
    "\n",
    "rf_mean_accuracy, rf_stddev_accuracy = predict_classifier_test_accuracy(rf_clf, X_train, y_train)\n",
    "print('*** RF Classifier ***')\n",
    "print('    Mean:', rf_mean_accuracy)\n",
    "print('Std.dev.:', rf_stddev_accuracy)\n",
    "print()\n",
    "\n",
    "# Compare expected accuracy to true test accuracy. Difference should be small!\n",
    "print('Comparing to test accuracy ...')\n",
    "assert(np.abs(sgd_mean_accuracy - sgd_test_accuracy) < 0.1)\n",
    "assert(np.abs(dt_mean_accuracy - dt_test_accuracy) < 0.1)\n",
    "assert(np.abs(rf_mean_accuracy - rf_test_accuracy) < 0.1)\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d853d39e37c13653de6b6085f3febd6b",
     "grade": false,
     "grade_id": "cell-6f115cce9cbb8e77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Visualize the results\n",
    "\n",
    "It is important to not only look at statistics, but also to confirm yourself that the statistics make sense.\n",
    "Let's visualize the classification results by drawing the predicted labels back on the respective images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_classification_results(clf, img_idx, Ps_test, labels_test, points_test, imgids_test):\n",
    "    mask = imgids_test == img_idx\n",
    "\n",
    "    y_test_pred = clf.predict(Ps_test[mask])\n",
    "    y_test_pred_prob = clf.predict_proba(Ps_test[mask])\n",
    "    points = points_test[mask,:]\n",
    "\n",
    "    confmat = confusion_matrix(labels_test[mask], y_test_pred)\n",
    "    accuracy = accuracy_score(labels_test[mask], y_test_pred)\n",
    "    #jaccard = sklearn.metrics.jaccard_score(labels_test[mask], y_test_pred, average='macro')\n",
    "\n",
    "    print(f' confusion matrix:')\n",
    "    print(confmat)\n",
    "    print(f' accuracy: {accuracy:.3f}')\n",
    "    #print(f'  jaccard: {jaccard:.3f}')\n",
    "\n",
    "    best_idx1 = y_test_pred_prob[:,1].argmax()\n",
    "    best_idx2 = y_test_pred_prob[:,2].argmax()\n",
    "    \n",
    "    # load image\n",
    "    I = Is[img_idx]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(I)\n",
    "    plt.plot(points[y_test_pred==0, 0], points[y_test_pred==0, 1], '.r')\n",
    "    plt.plot(points[y_test_pred==3, 0], points[y_test_pred==3, 1], '.y')\n",
    "    plt.plot(points[y_test_pred==1, 0], points[y_test_pred==1, 1], '.g')\n",
    "    plt.plot(points[y_test_pred==2, 0], points[y_test_pred==2, 1], '.b')\n",
    "    plt.plot(points[(best_idx1, best_idx2), 0], points[(best_idx1, best_idx2), 1], 'c-', linewidth=2)\n",
    "    plt.plot(points[best_idx1, 0], points[best_idx1, 1], 'co')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On TRAIN data\n",
    "train_img_idxs = np.unique(imgids_train)\n",
    "classifiers = {'Logistic Regression': sgd_clf, 'Random Forest': rf_clf, 'Decision-Tree': dt_clf}\n",
    "\n",
    "def plot_nth_train_result(clf, n):\n",
    "    plot_image_classification_results(clf, train_img_idxs[n], X_train, y_train, points_train, imgids_train)\n",
    "\n",
    "ipywidgets.interact(plot_nth_train_result, clf=classifiers, n=(0,len(train_img_idxs)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On TEST data\n",
    "test_img_idxs = np.unique(imgids_test)\n",
    "classifiers = {'Logistic Regression': sgd_clf, 'Random Forest': rf_clf, 'Decision-Tree': dt_clf}\n",
    "\n",
    "def plot_nth_test_result(clf, n):\n",
    "    plot_image_classification_results(clf, test_img_idxs[n], X_test, y_test, points_test, imgids_test)\n",
    "\n",
    "ipywidgets.interact(plot_nth_test_result, clf=classifiers, n=(0,len(test_img_idxs)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm with visual inspection if the evaluation statistics make sense.\n",
    "For instance, try to see if you find any patterns in the errors that the classifiers make,\n",
    "and under what conditions most errors occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "867f750267ddf5c8a9d37563b1d527ec",
     "grade": false,
     "grade_id": "cell-e4a6cd674165639f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Test on uniformly sampled grid (strategy 1)\n",
    "\n",
    "It may look like the classification task has been solved, however our procedure to extract the patches from the training and testing images oversamples non-background locations. While this results in more balanced classes, this is not realistic for how the detector could be used in practice. In a true test case, we don't already know where the pen is located. We should therefore re-investigate our test images, and check what the test performance is on uniformly distributed patches.\n",
    "\n",
    "Let's use the classifiers that were already trained on strategy 1, and see what their test performance is on strategy 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2, y_test2, points_test2, imgids_test2 = extract_multiple_images(test_imgs, strategy=1)\n",
    "\n",
    "print('Overal class count:')\n",
    "print(count_classes(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On TEST data\n",
    "test_img_idxs2 = np.unique(imgids_test2)\n",
    "classifiers = {'Logistic Regression': sgd_clf, 'Random Forest': rf_clf, 'Decision-Tree': dt_clf}\n",
    "\n",
    "def plot_nth_test_result2(clf, n):\n",
    "    plot_image_classification_results(clf, test_img_idxs2[n], X_test2, y_test2, points_test2, imgids_test2)\n",
    "\n",
    "ipywidgets.interact(plot_nth_test_result2, clf=classifiers, n=(0,len(test_img_idxs2)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, if you compare the accuracy between the sampling strategies for the same test image and same classifier, you may notice that often the accuracy on the uniform grid (strategy 1) is higher. The test classes are so unbalanced, and as long as a classifier can get most of the \"easy\" background patches correct, it will obtain a high accuracy.\n",
    "\n",
    "On the other hand, visually the classifiers seem to make many more mistakes, and we see that the classifiers often misclassify large regions in the image. Maybe the classifiers are too 'eager' to classify patches as pen-parts as in the training data these classes were more likely to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9ddce83db0888621c255e590fca2433",
     "grade": false,
     "grade_id": "cell-cd4c4c61971ca855",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Timing evaluation\n",
    "\n",
    "Let's also try to see how we can use the jupyter notebook to get some quick and dirty timing results for when you are running some experiments. Keeping an eye on how long a particular computation steps takes can be important when planning your experiments, and to figure out how your problems scale with larger and more complex datasets.\n",
    "\n",
    "We'll focus on timing the training and testing phases of the classifiers. Note that a proper timing evaluation requires running each procedure multiple times, but here we will skip this step and only fit each model once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint*: you can use the special command `%%time` at the start of a notebook cell to report the amount of time in seconds in took to execute a cell.\n",
    "To illustrate this, we have some simple examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_function():\n",
    "    # this is a dummy function which does nothing, but just waits for 0.5 seconds to illustrate time profiling\n",
    "    import time\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using %time\n",
    "#   Note that %time is a \"magic\" jupyter notebook command, and not actual python code\n",
    "#   the %time command automatically times the execution spped of the command following it\n",
    "\n",
    "%time slow_function() # timed\n",
    "slow_function() # not timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Example of using %%time\n",
    "#   Note that %%time is a \"magic\" cell command, which applies to the whole cell rather than a single line.\n",
    "#   Note how the cell STARTS with the %%time command\n",
    "\n",
    "# whole cell is timed\n",
    "slow_function()\n",
    "slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to train each classifier on your computer?\n",
    "Report your results here (it is sufficient to print the timing results in the output, you don't need to store these numbers in variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d43e45abdf06a6a4aa11d6cf293fb10",
     "grade": false,
     "grade_id": "cell-4f1431cc3b4e5425",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb87309c5016f8a4a1f87df06fb5892a",
     "grade": false,
     "grade_id": "cell-44961510919d57b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now test the how long it takes each classifier to make a prediction on all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96c3d886a73356979ad11cee23b44d18",
     "grade": false,
     "grade_id": "cell-77df663ca235e616",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Based on these time results, which method will have the least latency when processing images sequentially on a live video stream from the robot?\n",
    "\n",
    "Answer by uncommenting only the correct option from the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16e15a18f8d00e9b4d627b249d3e62d9",
     "grade": false,
     "grade_id": "cell-4cd7eb511974fb9e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer by uncommenting only the correct option from this block below\n",
    "ANSWER_LOWEST_LATENCY = 'no answer given yet ...'\n",
    "#ANSWER_LOWEST_LATENCY = 'Logistic Regression'\n",
    "#ANSWER_LOWEST_LATENCY = 'Decision Tree'\n",
    "#ANSWER_LOWEST_LATENCY = 'Random Forest'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b90882851cdf16cd17bb0280987c6a94",
     "grade": true,
     "grade_id": "cell-2b06f9e66f11bba2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Your answer: ', ANSWER_LOWEST_LATENCY)\n",
    "\n",
    "# to answer, you should have selected one of the three options ...\n",
    "assert(ANSWER_LOWEST_LATENCY in ('Logistic Regression', 'Decision Tree', 'Random Forest'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test models with your own data\n",
    "\n",
    "The final task of this practicum is that you and your lab partner do your *own* data collection and annotation,\n",
    "\n",
    "The following instructions should be done *indepdently* by both lab partners:\n",
    "* Collect several images of your pen with your phone, the resoution should be at least 1024 pixels in width and height.\n",
    "* Take the pictures from above your desk from a more or less fixed distance to the pen, similar to the images used in the previous experiments.\n",
    "* Make sure you rotate the pen everytime such that it always appears at slightly different angles and locations in the images.\n",
    "* Copy the images from your phone to a new subfolder in the `images/` directory. This could be done via a usb cable, wireless transfer, or some cloud service that you can access or your phone or computer. I'm sure you'll be able to figure something out ;) More specifically:\n",
    "    * place the images from the first lab partner in to the `images/lab_partner1/` directory\n",
    "    * place the images from the second lab partner in to the `images/lab_partner2/` directory\n",
    "    * (see how is lab partner 1 and how is lab partner 2 in the first code cell at the top of this notebook)\n",
    "* Annotate the start and end points of the pen in all iamges using the provided `Data annotator.ipynb`, which will also resize the images such that the max height or width of 1024 pixels. This way, all extract image $100 \\times 100$ image patches should show more or less a similar size.\n",
    "* Ensure you have at least about 20 images for training, and 10 images for testing.\n",
    "* Exchange your annotated dataset with your lab partner, such that you both have the same filled image directories on your computers.\n",
    "\n",
    "**NOTE:** We will ask you to upload your own annotated image directories to get with this worked out notebook. We may share your datasets with other students in this course for a follow-up experiment. Make sure you have **no sensitive or unappropriate content** in the images that you use, and that you are okay with others seeing them too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4afe024eaec4744051649fb8111b4734",
     "grade": false,
     "grade_id": "cell-a335c7723b778000",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Train a classifier on the images of lab partner 1\n",
    "\n",
    "Using the data of the first lab partner,\n",
    "* Prepare a training and testing dataset, similar to what we did before (using the 2nd patch sampling strategy). You can use all the functions that have been defined above, you don't need to redefine those.\n",
    "* On this dataset select a classifier, and compute test performance.\n",
    "* Report the accuracy and confusion matrix of the selected classifier on the test dataset.\n",
    "\n",
    "You are free to add cells below to complete this task, we'll only add a check that the images are found in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1c2ad3ae15851bd8c0be45d10fc3c3e",
     "grade": false,
     "grade_id": "cell-fc0cb07f2676b8da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "partner1_filenames = list_images('images/lab_partner1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e61b0c7c32d483930636d78267a4b29b",
     "grade": true,
     "grade_id": "cell-af01ca7f2386333a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(partner1_filenames) >= 30) # we need at least 30 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bb94d7df4e4531f41413c03075ddbf4",
     "grade": false,
     "grade_id": "cell-e8d1516a4f8697ee",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Train a classifier on the images of lab partner 2\n",
    "\n",
    "Do the same for the images the second lab partner here below. Same rules apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ad7d2cc17da91f4917b67c5c9cf9880",
     "grade": false,
     "grade_id": "cell-f0780531101dc1a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "partner2_filenames = list_images('images/lab_partner2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(partner2_filenames) >= 30) # we need at least 30 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "377c89cf9dc64077af0c716670fa0dc8",
     "grade": false,
     "grade_id": "cell-7688bd5dd9be36ce",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "As the final step, let's see how well your classifier generalizes to new data that has been collected independently of the training data. This is what often happens we we use pre-trained classifiers from another lab, or when a robot is placed in a different environment than where it was developed.\n",
    "\n",
    "Add code below to take the trained classifier on the **training data** of **lab partner 2**, and evaluate how well it performs on the **test data** of **lab partner 1**.\n",
    "Apart from some statistics, also visually inspect the classification result.\n",
    "Finish with a Markdown cell where you explain your observations: how well did the classifier perform on the other dataset? Is that better or worse than you both expected? Can you see what kind of patches it is misclassifying?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finishes this week's practicum! \n",
    "Please zip your saved notebook with your solutions, and don't forgot to include this zip also your and your labpartner's annotated datasets.\n",
    "Each dataset directory should contain the annotations you created, and the images you collected (but only the ones resixed to max dimensions of 1024 pixels by the \"Data annotator\" tool, not your huge original high-resolution pictures!).\n",
    "Hopefully if we collect a large and diverse dataset from all students, we can make our robot more robustly pickup pens or its collections :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
