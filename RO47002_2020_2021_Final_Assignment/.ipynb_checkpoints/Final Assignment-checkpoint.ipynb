{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Assignment \n",
    "# Machine Learning for Robotics (RO47002) 2020/2021\n",
    "\n",
    "Group Number:\n",
    "\n",
    "Student 1 (name + student number):\n",
    "\n",
    "Student 2 (name + student number):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Note: Please remove this cell for the submission.*\n",
    "\n",
    "## Task Description\n",
    "In this final assignment, we revisit our robot from Practicum 2, which was able to pick up a pen after you trained it to recognize parts of the pen in its camera images. Now we want to teach the robot to be able to clean up a table after a meal. In particular, it needs to be able to pick up cutlery (forks, knives, spoons).  For that the robot needs to determine where the cutlery is located and where the handle is. The robot has a basic down-facing camera that it can place on top of the desk to inspect an area of interest. Your task is to design the machine learning method for this perception problem. To simplify the problem, we'll only consider a single type of cutlery (your choice of fork, spoon, or knife) and a single object visible in each camera picture.\n",
    "\n",
    "## Deliverables\n",
    "The deadline is Sunday October 25th, 23:59. Late submission is –1 grade point per day.\n",
    "\n",
    "The main deliverable is a Jupyter Notebook, integrating the report (markdown cells) and the code. Submission is again in the form of a single ZIP file that includes all files required to run the notebook and reproduce the results (collected images, annotation data, loadable parameters, auxiliary scripts, etc.). The notebook needs to be able to run within 10 minutes on a high-end PC, performing all steps (also including the hyperparameter optimization and training).  Unlike previous lab assignments, there are no autograded cells or asserts, but we will grade the notebook manually. Therefore, you are free to add cells as you see fit, as long as the required sections are still present in the notebook.\n",
    "\n",
    "## Grading Criteria\n",
    "Below you will find an outline of the sections that the notebook needs to contain and what we expect for each part. More specific requirements are listed there as well. The indicated number of points, out of a total of 100, should give you a rough indication on how much effort to put into each part.\n",
    "\n",
    "In general, we will not focus as much on the performance of the method you design, but rather the _level of understanding and argumentation about your design choices_. So, we are not only interested in WHAT you did, but will put a strong emphasis on your reasoning about the WHY. Try to synthesize rather than describing what you did step by step.\n",
    "\n",
    "### Quality of the Report (20 points)\n",
    "- Structure & Readability\n",
    " - Logical flow\n",
    " - Connection between parts\n",
    "- English\n",
    " - Do not use short forms, like \"isn't\", \"wouldn't\".\n",
    " - Do not use colloquial style, like \"a couple of\".\n",
    " - Spell check and proofread your report.\n",
    "- Level of detail\n",
    " - Strive for elegant, concise text - longer reports do not necessarily yield higher grades.\n",
    " - There is no need to re-explain theory. Assume that the target audience of the report has followed the course.\n",
    "- Figures & Tables\n",
    " - Choose figures/plots/tables carefully. Only include those that add to the story of the report. Do not put the burden on the reviewer to figure out which results you basing your conclusions on, but specifically refer (parts of) the specific table/plot/figure when needed.\n",
    " - When comparing two or more signals display them in one plot. Explain the colors / line types. The scale of the plots must be carefully chosen in order to clearly convey the information intended. Label properly the axes in graphs (variables and units).\n",
    "- Citations\n",
    " - If you use images, theory and methods beyond what was covered in the course, etc., always reference sources.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "*Note: Please do not include the requirements in the submission.*\n",
    "\n",
    "# Structure (inspired by the Machine Learning Project Checklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame the Problem and Look at the Big Picture (10 points)\n",
    "- How do you frame the learning problem? Please treat the main learning problem as a supervised learning problem. But can you best express it as a classification problem, a regression problem, an image segmentation problem, etc.? Note that there is not one best answer to this question, and the task could be addressed in different ways. We want to know your motivation for your selected approach.\n",
    "- What are the runtime constraints, especially for predictions? How fast does the robot need to be able to process an image? What kind of platform do you assume (e.g., Arduino, Laptop, etc.)?\n",
    "- How should performance be measured? What is the minimum performance required? What are the objectives? What kind of loss function is appropriate?\n",
    "- What are promising algorithms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data (15 points)\n",
    "- Collect your own dataset, i.e., take pictures of your chosen type of cutlery on a table. What was your protocol? How many pictures do you need? What kind of variations did you try to capture? What kind of potential variations are you trying to avoid to capture?\n",
    "- Annotate the data. Explain which options you considered and what you did in the end. If it is a custom annotation tool, include it in the submission, if you used an external tool, a link is sufficient\n",
    "- Sample a test set\n",
    "- *Note:* In contrast to Practicum 2, it is sufficient to just collect a single dataset and perform the training/testing split on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using knife images for training out dataset. Different kind of knives are selected with the different background. \n",
    "Annotation tool used was the one providd with Practicum 2.\n",
    "Since we are not using a dataset which is dynamic we do not need compute the hash of each instances identifier.\n",
    "\n",
    "To avoid the data snopping error we will split the dataset with the random seed constant so that the classifier is not trained on the test data set at all. We will keep the 20% of the dataset for the test purpose and the selection of the dataset will be random after shuffiling. To get the same shuffle and the same split of the data we will keep the random state of the test_train_split function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data from the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data (5 points)\n",
    "- Visualize the data\n",
    "- Study its properties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data (10 points)\n",
    "- Pre-process the data (e.g. down-sample, color channels)\n",
    "- Extract features (if needed by chosen algorithms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortlist Promising Models (15 points)\n",
    "- Compare at least 2 models. One of them needs to be a neural network, one of them needs to be not a neural network.\n",
    "- Perform dimensionality reduction (if needed)\n",
    "- Roughly tune those models\n",
    "- Evaluate the models in terms of performance, bias, variance, etc.\n",
    "- Pick one algorithm to develop further\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune the System (15 points)\n",
    "- Perform hyperparameter optimization (including pre-processing steps)\n",
    "- Evaluate the final model (similar to “Shortlist Promising Models” above)\n",
    "- Evaluate if your dataset was large and rich enough\n",
    "- Save the parameters of your best model to your harddrive (use pickle for sklearn or built-in save/load for keras), you will need to be able to reload your model without training in the next step. Be sure to include the saved parameters in your zip file so we can evaluate your best model too even without rerunning the notebook up to here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present Your Solution (10 points)\n",
    "- Summarize your main decisions and insights\n",
    "- Create a stand-alone demo. I.e., a block of cells that can be run on its own. For that you will need to load your pre-trained best model you saved in the previous section, measure its performance on the test set, present results both in numbers and with illustrative examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Develop Your System (Bonus, max 10 points)\n",
    "- With this part you can make up for lost points in the main part. The maximum grade is still a 10. \n",
    "- Extend the system to work with either multiple types of cutlery, or multiple objects in a camera image, or different tables, or distractor objects, or different brands of your chosen type of cutlery, or a combination thereof.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
